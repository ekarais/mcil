{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "from sparse_net import SparseNet\n",
    "import hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "dataset = \"mnist\"\n",
    "continual = True\n",
    "config = hyperparameters.mnist\n",
    "config[\"data_dir\"] = \"/home/ekarais/mcil/data/\"\n",
    "config[\"num_epochs\"] = 5\n",
    "config[\"network_hyperparameters\"][\"k\"] = 10\n",
    "config[\"network_hyperparameters\"][\"n\"] = 150\n",
    "config[\"continual_batch_size\"] = 128\n",
    "config[\"continual_learning_rate\"] = 1e-5\n",
    "config[\"continual_num_classes\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continual_split(dataset, num_classes=1):\n",
    "    train_dataset = torch.utils.data.Subset(dataset, [idx for idx, label in enumerate(dataset.train_labels) if label in range(10-num_classes)])\n",
    "    continual_loaders = []\n",
    "    for class_idx in range(10-num_classes, 10):\n",
    "        marginal_dataset = torch.utils.data.Subset(dataset, [idx for idx, label in enumerate(dataset.train_labels) if label == class_idx])\n",
    "        continual_loaders.append(DataLoader(marginal_dataset, batch_size=config[\"continual_batch_size\"], shuffle=True))\n",
    "    return train_dataset, continual_loaders\n",
    "\n",
    "def contrastive_divergence(logits, labels):\n",
    "    \"\"\"\n",
    "    TODO: Try out Perceptron analogous rule that only updates after mistakes\n",
    "    \"\"\"\n",
    "    num_samples = labels.shape[0]\n",
    "    random_idc = torch.randint(0, 10, (num_samples,))\n",
    "    return torch.sum(logits[range(num_samples), random_idc]) - torch.sum(logits[range(num_samples), labels])\n",
    "    \"\"\"\n",
    "    for i in range(labels.shape[0]):\n",
    "        pred = torch.argmax(logits[i]).item()\n",
    "        if pred == labels[i]:\n",
    "            random_idx = random.randint(0, 9)\n",
    "            loss += logits[random_idx] - logits[labels[i]]\n",
    "        else:\n",
    "            loss += logits[pred] - logits[labels[i]]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekarais/miniconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"mnist\":\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_dataset = MNIST(config[\"data_dir\"], train=True, download=True, transform=transform)\n",
    "    test_dataset = MNIST(config[\"data_dir\"], train=False, download=True, transform=transform)\n",
    "\n",
    "if dataset == \"cifar10\":\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "if continual:\n",
    "    train_dataset, continual_loaders = get_continual_split(train_dataset, num_classes=config[\"continual_num_classes\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "fe_loader = DataLoader(train_dataset, batch_size=config[\"first_epoch_batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"test_batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create neural network, optimizer, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SparseNet(**config[\"network_hyperparameters\"]).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"lr_scheduler_params\"][\"step_size\"], gamma=config[\"lr_scheduler_params\"][\"gamma\"])\n",
    "criterion = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 0.5066, loss = 4.5004\n",
      "Epoch 2: Accuracy = 0.5091, loss = 4.8103\n",
      "Epoch 3: Accuracy = 0.5088, loss = 5.0033\n",
      "Epoch 4: Accuracy = 0.5091, loss = 5.0353\n",
      "Epoch 5: Accuracy = 0.5090, loss = 5.0958\n"
     ]
    }
   ],
   "source": [
    "accuracies, losses = [], [] * 10\n",
    "\n",
    "for e in range(config[\"num_epochs\"]):\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "\n",
    "    loader = train_loader if e > 0 else fe_loader\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    loss, correct = 0, 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss += criterion(y_pred, y)\n",
    "        pred = y_pred.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    # Print results\n",
    "    losses.append(loss.item() / len(test_loader))\n",
    "    accuracies.append(correct / len(test_dataset))\n",
    "\n",
    "    print(f\"Epoch {e+1}: Accuracy = {accuracies[-1]:.4f}, loss = {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Accuracy = 0.5158, loss = 4.1279\n",
      "Epoch 7: Accuracy = 0.5299, loss = 3.3610\n",
      "Epoch 8: Accuracy = 0.5565, loss = 2.7076\n",
      "Epoch 9: Accuracy = 0.5230, loss = 2.3315\n",
      "Epoch 10: Accuracy = 0.2301, loss = 5.8337\n"
     ]
    }
   ],
   "source": [
    "if continual:\n",
    "    model_cp = copy.deepcopy(model)\n",
    "    optimizer_cp = torch.optim.SGD(model_cp.parameters(), lr=config[\"continual_learning_rate\"])\n",
    "\n",
    "    # Freeze everything except last layer\n",
    "    for param in model_cp.cnnSdr:\n",
    "        param.requires_grad = False\n",
    "\n",
    "    \"\"\"\n",
    "    for param in model_cp.linearSdr:\n",
    "        param.requires_grad = False\n",
    "    \"\"\"\n",
    "    \n",
    "    for e, loader in enumerate(continual_loaders):\n",
    "        \n",
    "        # Train\n",
    "        model_cp.train()\n",
    "\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer_cp.zero_grad()\n",
    "            y_pred = model_cp(x)\n",
    "            loss = contrastive_divergence(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer_cp.step()\n",
    "\n",
    "        # Test\n",
    "        model_cp.eval()\n",
    "        loss, correct = 0, 0\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer_cp.zero_grad()\n",
    "            y_pred = model_cp(x)\n",
    "            loss += criterion(y_pred, y)\n",
    "            pred = y_pred.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "        \n",
    "        #scheduler.step()\n",
    "\n",
    "        # Print results\n",
    "        losses.append(loss.item() / len(test_loader))\n",
    "        accuracies.append(correct / len(test_dataset))\n",
    "        print(f\"Epoch {e+6}: Accuracy = {accuracies[-1]:.4f}, loss = {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k/n = 0.5, cbatch_size = 64, num_classes=5  \n",
    "- Epoch 1: Accuracy = 0.5064, loss = 5.0463\n",
    "- Epoch 2: Accuracy = 0.5102, loss = 5.0519\n",
    "- Epoch 3: Accuracy = 0.5100, loss = 5.0688\n",
    "- Epoch 4: Accuracy = 0.5103, loss = 5.1469\n",
    "- Epoch 5: Accuracy = 0.5102, loss = 5.1847\n",
    "- Epoch 6: Accuracy = 0.3469, loss = 5.0968\n",
    "- Epoch 7: Accuracy = 0.2971, loss = 3.9103\n",
    "- Epoch 8: Accuracy = 0.1926, loss = 4.3945\n",
    "- Epoch 9: Accuracy = 0.1632, loss = 3.4623\n",
    "- Epoch 10: Accuracy = 0.2637, loss = 2.6053\n",
    "\n",
    "k/n = 0.1, cbatch_size = 64, num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5082, loss = 4.3091\n",
    "- Epoch 2: Accuracy = 0.5088, loss = 4.4989\n",
    "- Epoch 3: Accuracy = 0.5093, loss = 4.6351\n",
    "- Epoch 4: Accuracy = 0.5090, loss = 4.6894\n",
    "- Epoch 5: Accuracy = 0.5093, loss = 4.7322\n",
    "- Epoch 6: Accuracy = 0.3744, loss = 4.1252\n",
    "- Epoch 7: Accuracy = 0.2844, loss = 4.0484\n",
    "- Epoch 8: Accuracy = 0.1992, loss = 4.5525\n",
    "- Epoch 9: Accuracy = 0.1762, loss = 3.8198\n",
    "- Epoch 10: Accuracy = 0.1911, loss = 3.5139\n",
    "\n",
    "k/n = 0.1, cbatch_size = 1000, num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5099, loss = 4.9009\n",
    "- Epoch 2: Accuracy = 0.5102, loss = 4.9802\n",
    "- Epoch 3: Accuracy = 0.5102, loss = 5.0313\n",
    "- Epoch 4: Accuracy = 0.5104, loss = 5.0584\n",
    "- Epoch 5: Accuracy = 0.5101, loss = 5.0824\n",
    "- Epoch 6: Accuracy = 0.4992, loss = 3.6592\n",
    "- Epoch 7: Accuracy = 0.5080, loss = 2.5587\n",
    "- Epoch 8: Accuracy = 0.5078, loss = 2.1479\n",
    "- Epoch 9: Accuracy = 0.5079, loss = 1.8950\n",
    "- Epoch 10: Accuracy = 0.5062, loss = 1.7333\n",
    "\n",
    "k/n = 0.1, cbatch_size = 2000, num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5082, loss = 4.6018\n",
    "- Epoch 2: Accuracy = 0.5097, loss = 4.7513\n",
    "- Epoch 3: Accuracy = 0.5104, loss = 4.8468\n",
    "- Epoch 4: Accuracy = 0.5101, loss = 4.8978\n",
    "- Epoch 5: Accuracy = 0.5101, loss = 4.9481\n",
    "- Epoch 6: Accuracy = 0.4510, loss = 3.5416\n",
    "- Epoch 7: Accuracy = 0.4117, loss = 3.4274\n",
    "- Epoch 8: Accuracy = 0.2813, loss = 2.4435\n",
    "- Epoch 9: Accuracy = 0.2189, loss = 4.2437\n",
    "- Epoch 10: Accuracy = 0.2096, loss = 2.9414\n",
    "\n",
    "k/n = 0.1, cbatch_size = 1000 (frozen except final layer), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5085, loss = 4.7954\n",
    "- Epoch 2: Accuracy = 0.5094, loss = 4.7900\n",
    "- Epoch 3: Accuracy = 0.5090, loss = 4.7555\n",
    "- Epoch 4: Accuracy = 0.5090, loss = 4.7553\n",
    "- Epoch 5: Accuracy = 0.5087, loss = 4.8191\n",
    "- Epoch 6: Accuracy = 0.4866, loss = 3.1440\n",
    "- Epoch 7: Accuracy = 0.5011, loss = 2.4275\n",
    "- Epoch 8: Accuracy = 0.4972, loss = 1.9922\n",
    "- Epoch 9: Accuracy = 0.4980, loss = 1.7820\n",
    "- Epoch 10: Accuracy = 0.4951, loss = 1.6539\n",
    "\n",
    "### Takeaways\n",
    "- Reducing k/n alone does not seem to mitigate CF.\n",
    "- Once in the continual learning (CL) regime, the loss and accuracy start dropping together, which is unusual. \n",
    "- By strongly increasing the CL regime batch size (effectively reducing the number of parameter updates), we can bring down the loss significantly more (3.5 to 1.7) and suffer no CF, but the accuracy does not improve either. This benefit seems to be lost if we increase CL regime batch size even further.\n",
    "- Freezing everything except the final hidden layer only helps a little, potentially not at all.\n",
    "- All findings above are based on single executions, better re-run experiments multiple times for certainty.\n",
    "\n",
    "### Next steps\n",
    "- Reduce k/n even further by increasing n a lot, then only freeze the cnn and use large batch size => does not change anything. I realized that this is because the final decision layer is densely updated...\n",
    "- Use contrastive divergence ALSO during i.i.d training.\n",
    "- Use contrastive divergence on dense network, compare results\n",
    "- plot confusion matrix\n",
    "- compute activation overlaps somehow\n",
    "- Set number of continual learning classes to 1\n",
    "\n",
    "k/n = 0.1, cbatch_size = 1000 (frozen cnn + contrastive divergence during CL), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5093, loss = 4.3138\n",
    "- Epoch 2: Accuracy = 0.5096, loss = 4.5218\n",
    "- Epoch 3: Accuracy = 0.5100, loss = 4.6063\n",
    "- Epoch 4: Accuracy = 0.5101, loss = 4.6912\n",
    "- Epoch 5: Accuracy = 0.5101, loss = 4.7616\n",
    "- Epoch 6: Accuracy = 0.5070, loss = 4.1733\n",
    "- Epoch 7: Accuracy = 0.5109, loss = 3.2822\n",
    "- Epoch 8: Accuracy = 0.5085, loss = 2.4707\n",
    "- Epoch 9: Accuracy = 0.5075, loss = 1.8425\n",
    "- Epoch 10: Accuracy = 0.5175, loss = **1.3504**\n",
    "\n",
    "k/n = 0.1, cbatch_size = 512 (frozen cnn + contrastive divergence during CL), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5091, loss = 4.1679\n",
    "- Epoch 2: Accuracy = 0.5096, loss = 4.3857\n",
    "- Epoch 3: Accuracy = 0.5098, loss = 4.4505\n",
    "- Epoch 4: Accuracy = 0.5100, loss = 4.5395\n",
    "- Epoch 5: Accuracy = 0.5102, loss = 4.6221\n",
    "- Epoch 6: Accuracy = 0.5095, loss = 4.4327\n",
    "- Epoch 7: Accuracy = 0.5563, loss = 4.0115\n",
    "- Epoch 8: Accuracy = 0.5821, loss = 3.4107\n",
    "- Epoch 9: Accuracy = 0.2740, loss = 4.4475\n",
    "- Epoch 10: Accuracy = 0.1011, loss = 13.0413\n",
    "\n",
    "\n",
    "k/n = 0.1, cbatch_size = 256 (frozen cnn + contrastive divergence during CL), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5083, loss = 4.5104\n",
    "- Epoch 2: Accuracy = 0.5101, loss = 4.6225\n",
    "- Epoch 3: Accuracy = 0.5104, loss = 4.7108\n",
    "- Epoch 4: Accuracy = 0.5103, loss = 4.7927\n",
    "- Epoch 5: Accuracy = 0.5103, loss = 4.8529\n",
    "- Epoch 6: Accuracy = 0.5122, loss = 4.3171\n",
    "- Epoch 7: Accuracy = 0.5396, loss = 3.3979\n",
    "- Epoch 8: Accuracy = 0.5387, loss = 2.5908\n",
    "- Epoch 9: Accuracy = 0.5651, loss = 1.7700\n",
    "- Epoch 10: Accuracy = 0.5807, loss = 1.3371\n",
    "\n",
    "k/n = 0.1, cbatch_size = 128 (frozen cnn + contrastive divergence during CL), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5086, loss = 4.0126\n",
    "- Epoch 2: Accuracy = 0.5089, loss = 4.2935\n",
    "- Epoch 6: Accuracy = 0.5077, loss = 4.1278\n",
    "- Epoch 7: Accuracy = 0.5084, loss = 3.4736\n",
    "- Epoch 8: Accuracy = 0.5108, loss = 2.5882\n",
    "- Epoch 9: Accuracy = 0.5568, loss = 1.7713\n",
    "- Epoch 10: Accuracy = 0.6177, loss = 1.1573\n",
    "\n",
    "k/n = 0.1, cbatch_size = 64 (frozen cnn + contrastive divergence during CL), num_classes=5\n",
    "- Epoch 1: Accuracy = 0.5087, loss = 4.3742\n",
    "- Epoch 2: Accuracy = 0.5106, loss = 4.4751\n",
    "- Epoch 3: Accuracy = 0.5099, loss = 4.6011\n",
    "- Epoch 4: Accuracy = 0.5099, loss = 4.6098\n",
    "- Epoch 5: Accuracy = 0.5097, loss = 4.6192\n",
    "- Epoch 6: Accuracy = 0.5080, loss = 4.0452\n",
    "- Epoch 7: Accuracy = 0.5397, loss = 3.3654\n",
    "- Epoch 8: Accuracy = 0.5884, loss = 2.5469\n",
    "- Epoch 9: Accuracy = 0.6041, loss = 1.7788\n",
    "- Epoch 10: Accuracy = 0.5887, loss = 1.2069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing hidden layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation. Accuracy = 0.509, loss = 5.095767\n"
     ]
    }
   ],
   "source": [
    "# Code for saving hidden layer activations\n",
    "hidden_activations = {\"cnn\" : [], \"linear\" : []}\n",
    "\n",
    "def get_hidden_activations(name):\n",
    "    def hook(model, input, output):\n",
    "        hidden_activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.cnnSdr.register_forward_hook(get_hidden_activations(\"cnn\"))\n",
    "model.linearSdr.register_forward_hook(get_hidden_activations(\"linear\"))\n",
    "\n",
    "# Final evaluation \n",
    "model.eval()\n",
    "loss, correct = 0, 0\n",
    "batch_hidden_activations = []\n",
    "for x, y in test_loader:\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss += criterion(y_pred, y)\n",
    "    pred = y_pred.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    batch_hidden_activations.append((hidden_activations.copy(), y))\n",
    "\n",
    "# Print results\n",
    "loss /= len(test_loader)\n",
    "accuracy = correct / len(test_dataset)\n",
    "print(f\"Final evaluation. Accuracy = {accuracy:.3f}, loss = {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group hidden activations by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hidden_activations = functools.reduce(lambda a, b: torch.cat((a, b)), [item[0][\"linear\"] for item in batch_hidden_activations]).cpu().numpy()\n",
    "all_labels = functools.reduce(lambda a, b: torch.cat((a, b)), [item[1] for item in batch_hidden_activations]).cpu().numpy()\n",
    "\n",
    "activations_by_class = {}\n",
    "for i in range(10):\n",
    "    activations_by_class[i] = np.array(all_hidden_activations[np.where(all_labels == i)], dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize mean activation vector for given label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 150 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 8\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.bar(range(150), np.mean(activations_by_class[label], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71a75e0e45db768eaebc31dea91792615aa8f4634f9f6610c511235f2f9d372c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
